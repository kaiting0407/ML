# Problem 4.24 圖片解說與分析

## 實驗概述

本實驗探討**交叉驗證(Cross Validation)**在線性迴歸中的統計特性，特別是留一法交叉驗證(Leave-One-Out Cross Validation, LOOCV)的誤差分析。

### 實驗設定
- **維度**: d = 3
- **噪音標準差**: σ = 0.5  
- **樣本數**: N ∈ {18, 28, 38, ..., 118}（即 d+15 到 d+115，間隔10）
- **正規化參數**: λ = 0.05/N 和 λ = 2.5/N
- **實驗次數**: 10⁵ 次重複實驗

---

## Part (b): E[e₁], E[e₂], 與 E[E_cv] 的關係

### 📊 圖表說明（Pr4.24_part_b.png）

此圖展示三個量的平均值隨樣本數 N 變化的趨勢：
- **藍色圓點** (E[e₁]): 第一個交叉驗證誤差的期望值
- **橙色方點** (E[e₂]): 第二個交叉驗證誤差的期望值  
- **綠色三角** (E[E_cv]): 平均交叉驗證誤差的期望值

### 🔬 理論預測

根據交叉驗證理論：
$$E[e_1] = E[e_2] = \cdots = E[e_N] = E[E_{cv}]$$

這是因為每個 $e_i$ 都是在相同分佈下產生的：
- 訓練集有 N-1 個點
- 驗證集有 1 個點
- 所有 $e_i$ 都是獨立同分佈(i.i.d.)的隨機變數

### ✅ 實驗驗證

**數值結果**:
```
N = 18:
  E[e₁]  = 0.330842
  E[e₂]  = 0.331442
  E[E_cv] = 0.331218
  差異: 0.000375

N = 118:
  E[e₁]  = 0.259747
  E[e₂]  = 0.257958
  E[E_cv] = 0.258965
  差異: 0.000782
```

**學習現象**:
1. ✓ **三條曲線幾乎重合**，實驗結果完美驗證理論預測
2. ✓ **誤差隨 N 增加而減少**：N 越大，模型越穩定，泛化誤差越小
3. ✓ **差異極小**（< 0.001），顯示10⁵次實驗提供了高精確度的統計估計

---

## Part (c): Var[e₁] 的變異數分析

### 📊 圖表說明（Pr4.24_part_c.png）

此圖比較兩個變異數隨 N 變化的趨勢：
- **藍色曲線** (Var[e₁]): 單個交叉驗證誤差的變異數
- **紅色曲線** (Var[E_cv]): 平均交叉驗證誤差的變異數

### 🔬 變異數來源分析

**Var[e₁] 的主要貢獻者**：

1. **資料隨機性**: 
   - X ~ N(0, I) 的隨機抽樣
   - 不同實驗產生不同的訓練集

2. **噪音項**:
   - ε ~ N(0, 1)
   - y = w_f^T x + σε 中的隨機噪音

3. **留出點的隨機性**:
   - 不同的點被留出時，其誤差特性不同
   - 有些點可能是離群值，導致較大誤差

4. **正規化效應**:
   - λ 控制模型複雜度
   - 影響假設空間的變化

### 📈 觀察結果

**數值趨勢**:
```
N = 18:  Var[e₁] = 0.232271
N = 68:  Var[e₁] = 0.141772
N = 118: Var[e₁] = 0.136124

→ 變異數隨 N 增加而減少！
```

**學習現象**:
1. ✓ **Var[e₁] >> Var[E_cv]**：單點誤差的不確定性遠大於平均誤差
2. ✓ **Var[e₁] 遞減**：樣本數增加 → 模型更穩定 → 誤差變異性降低
3. ✓ **Var[E_cv] 快速遞減**：平均效應使變異數以 1/N 的速度下降

**理論解釋**:
- 當 N 增加，每個 CV 折的訓練集更大，模型估計更準確
- 訓練集大 → 權重向量 w_reg 更接近真實 w_f → 預測更穩定

---

## Part (e): 有效新樣本數 (N_eff)

### 📊 圖表說明（Pr4.24_part_e.png）

此圖包含兩個子圖：

**左圖**: N_eff vs N
- **綠色曲線**: 有效新樣本數 N_eff = Var[e_i] / Var[E_cv]
- **紅色虛線**: 理論參考線 y = N

**右圖**: N_eff/N 百分比
- **紫色曲線**: N_eff 佔 N 的百分比
- **紅色虛線**: 100% 參考線

### 🔬 理論基礎

**定義**: 
$$N_{eff} = \frac{Var[e_i]}{Var[E_{cv}]}$$

**物理意義**:
- 衡量有多少「有效獨立」的樣本在計算 E_cv
- 如果 e_i 完全獨立，則 Var[E_cv] = Var[e_i]/N，因此 N_eff = N
- 如果 e_i 高度相關，則 N_eff < N

**為什麼 e_i 可能相關？**
- 每個 e_i 的訓練集有 N-2 個共同點
- 共同訓練點 → 相似的模型 → CV 誤差相關

### 📈 實驗結果

**數值結果** (λ = 0.05/N):
```
N = 18:  N_eff = 13.67,  N_eff/N = 75.96%
N = 68:  N_eff = 63.60,  N_eff/N = 93.53%
N = 118: N_eff = 115.22, N_eff/N = 97.64%
```

**學習現象**:
1. ✓ **N_eff ≈ N**：有效樣本數非常接近實際樣本數
2. ✓ **隨 N 增加，N_eff/N → 100%**：大樣本下，CV 誤差幾乎獨立
3. ✓ **小 N 時偏差較大**：N=18 時只有 76%，因為共同訓練點比例高

**直覺理解**:
- 留一法 CV 的關鍵：每個 e_i 使用**不同的驗證點**
- 雖然訓練集重疊，但驗證點不同 → 誤差相對獨立
- N 越大，N-2 個共同點的影響越小 → 相關性降低

---

## Part (f): 正規化對 N_eff 的影響

### 📊 圖表說明

**Pr4.24_part_f_individual.png**: λ = 2.5/N 的 N_eff 分析  
**Pr4.24_part_f_comparison.png**: 兩種 λ 的比較

比較圖包含：
- **左圖**: 不同 λ 下的 N_eff 絕對值
- **右圖**: N_eff/N 百分比比較
  - 藍色: λ = 0.05/N（小正規化）
  - 橙色: λ = 2.5/N（大正規化）

### 🔬 理論推測

**假說**: 增加正規化 → N_eff 下降

**推理鏈**:
1. λ 增加 → 正規化更強
2. 正規化更強 → 模型更平滑、更簡單
3. 簡單模型 → 對訓練集變化不敏感
4. 留出不同點時，模型變化小
5. 模型相似 → e_i 更相關
6. 相關性高 → **N_eff 下降**

### 📈 實驗驗證

**數值結果**:
```
N = 18:
  λ = 0.05/N: N_eff/N = 75.96%
  λ = 2.5/N:  N_eff/N = 74.19%
  變化: -1.77 百分點 ✓

N = 118:
  λ = 0.05/N: N_eff/N = 97.64%
  λ = 2.5/N:  N_eff/N = 97.78%
  變化: +0.13 百分點
```

**學習現象**:
1. ✓ **小 N 時效應明顯**：N=18 時，大正規化使 N_eff/N 下降 1.77%
2. ✗ **大 N 時效應反轉**：N=118 時，大正規化反而使 N_eff/N 略增
3. ✓ **整體趨勢**：在中小樣本時，假說基本成立

**為何大 N 時效應反轉？**

可能原因：
- **競爭效應**：當 N 很大時
  - 正規化減少過擬合 → 模型更穩定 → Var[e_i] 下降
  - 同時 Var[E_cv] 也下降，但可能下降更快
  - 兩者比值反而增加

- **數值誤差**：0.13% 的差異在統計誤差範圍內

**結論**: 
假說在**小到中等樣本**時成立：**增加正規化 → N_eff 下降**  
但在大樣本時效應微弱或反轉，因為此時 CV 誤差已接近獨立 (>97%)

---

## 總結：關鍵學習現象

### 1️⃣ **交叉驗證的無偏性** (Part b)
- E[e_i] = E[E_cv]，無論哪個誤差都無偏估計泛化誤差
- 實驗完美驗證理論，差異 < 0.001

### 2️⃣ **平均效應降低變異** (Part c)
- Var[E_cv] ≈ Var[e_i] / N
- 平均 N 個誤差使變異數大幅降低

### 3️⃣ **CV 誤差的近似獨立性** (Part e)
- N_eff ≈ N，顯示留一法 CV 誤差幾乎獨立
- 關鍵：每個誤差使用不同驗證點
- 大 N 時獨立性更強 (>97%)

### 4️⃣ **正規化的雙重作用** (Part f)
- 小樣本：正規化 ↑ → 相關性 ↑ → N_eff ↓
- 大樣本：效應微弱，因為 CV 誤差已高度獨立
- Trade-off：偏差-變異數平衡

---

## 統計學意義

這個實驗深刻揭示了**交叉驗證的統計基礎**：

1. **可靠性**: CV 提供無偏的泛化誤差估計
2. **效率**: 留一法充分利用數據，N_eff ≈ N
3. **穩定性**: 平均效應大幅降低估計變異數
4. **適應性**: 正規化調節模型複雜度，影響 CV 行為

這些發現為**模型選擇和超參數調優**提供理論依據！

---

## 技術細節

**演算法**: Ridge Regression with LOOCV
$$w_{reg} = (X^T X + \lambda I)^{-1} X^T y$$

**交叉驗證誤差**:
$$e_i = (y_i - x_i^T w_{-i})^2$$
$$E_{cv} = \frac{1}{N} \sum_{i=1}^{N} e_i$$

**有效樣本數**:
$$N_{eff} = \frac{Var[e_i]}{Var[E_{cv}]}$$

---

*實驗完成於 2025年10月5日*  
*使用 100,000 次蒙特卡羅模擬*
