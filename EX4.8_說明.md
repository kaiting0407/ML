# Exercise 4.8 實驗結果說明

## 📋 題目要求

**Exercise 4.8 (20分)**
- **性質**: 程式實作 + 視覺化
- **指示**: 進行數值模擬並比較不同條件下的過擬合情況
- **答案要求**: 包含模擬結果的圖表
- **圖表說明**: 繪製訓練誤差和測試誤差曲線，並解釋隨著模型複雜度增加，誤差如何變化

---

## 🔬 實驗設計

### 實驗參數
依照題目中提到的 Exercise 4.2 實驗設計：
- **目標函數複雜度**: $Q_f = 3$ (3次多項式)
- **雜訊變異數**: $\sigma^2 = 0.4$
- **訓練樣本數**: $N = 35$
- **測試樣本數**: $N_{test} = 1000$
- **模型複雜度範圍**: 從1次到15次多項式
- **實驗重複次數**: 100次（取平均以降低隨機性）

### 目標函數
$$f(x) = 0.5x^3 - 0.3x^2 + 0.2x + 0.1$$

### 數據生成
$$y = f(x) + \varepsilon, \quad \varepsilon \sim \mathcal{N}(0, \sigma^2)$$

其中 $x$ 在 $[-1, 1]$ 範圍內均勻採樣。

---

## 📊 實驗結果

### 圖表 1: EX4.8_results.png

**左圖 - 訓練誤差 vs 測試誤差**
- **藍色實線** ($E_{in}$): 訓練誤差（In-sample error）
- **紅色實線** ($E_{out}$): 測試誤差（Out-of-sample error）
- **綠色虛線**: 目標函數的真實複雜度 $Q_f = 3$
- **灰色點線**: 雜訊水平 $\sigma^2 = 0.4$

**右圖 - 含標準差的誤差曲線**
- 陰影區域表示100次實驗的標準差範圍
- **橙色虛線**: 測試誤差最小的模型複雜度

### 圖表 2: EX4.8_overfitting_examples.png

展示四個不同複雜度模型的實際擬合情況：
- **Q=1**: 線性模型（欠擬合）
- **Q=3**: 與目標函數匹配（最佳）
- **Q=7**: 中度過擬合
- **Q=15**: 嚴重過擬合

---

## 📈 誤差變化分析

### 1. 訓練誤差 ($E_{in}$) 的變化

**觀察結果**:
- 隨著模型複雜度增加，訓練誤差**單調遞減**
- 從 $Q=1$ 的 0.3656 下降到 $Q=15$ 的 0.2046

**原因解釋**:
- 更複雜的模型有更多參數（自由度）
- 可以更精確地擬合訓練數據
- 即使是雜訊也會被擬合進去

**重要觀察**:
- 即使在 $Q=15$ 時，$E_{in} = 0.2046$ 仍然高於雜訊水平 $\sigma^2 = 0.4$
- 這是因為訓練樣本數有限（$N=35$）

### 2. 測試誤差 ($E_{out}$) 的變化

**觀察結果**:
- 呈現經典的 **U 型曲線**
- 最低點在 $Q=1$ 附近，$E_{out} = 0.4384$
- 隨後隨著複雜度增加而急劇上升
- $Q=15$ 時達到 504572.85（數值爆炸）

**三個階段**:

#### 階段 1: 欠擬合 ($Q < 3$)
- 模型複雜度不足以捕捉真實函數
- 高偏差（Bias）主導
- $E_{out}$ 相對較高

#### 階段 2: 適配良好 ($Q \approx 3$)
- 模型複雜度與目標函數匹配
- 偏差和變異數達到平衡
- 在 $Q=3$ 時，$E_{out} = 0.4554$ 接近雜訊水平

#### 階段 3: 過擬合 ($Q > 3$)
- 模型過於複雜，開始擬合雜訊
- 高變異數（Variance）主導
- $E_{out}$ 急劇增加
- 模型在新數據上泛化能力差

---

## 🎯 核心概念：偏差-變異數權衡 (Bias-Variance Tradeoff)

### 總誤差分解
$$E_{out} = \text{Bias}^2 + \text{Variance} + \text{Noise}$$

### 隨模型複雜度變化：

| 模型複雜度 | 偏差 (Bias) | 變異數 (Variance) | 總誤差 |
|-----------|------------|------------------|--------|
| **低** (Q=1) | ↑ 高 | ↓ 低 | 中等 |
| **適中** (Q=3) | ↓ 低 | ↑ 適中 | ✓ **最低** |
| **高** (Q=15) | ↓ 很低 | ↑↑ 很高 | ↑↑ 很高 |

### 視覺化解釋
從 **EX4.8_overfitting_examples.png** 可以看到：

- **Q=1** (左上): 直線無法捕捉曲線特徵 → **欠擬合**
- **Q=3** (右上): 平滑曲線完美匹配真實函數 → **剛剛好**
- **Q=7** (左下): 開始出現不必要的彎曲 → **輕度過擬合**
- **Q=15** (右下): 極度彎曲以通過每個訓練點 → **嚴重過擬合**

---

## ⚠️ 樂觀偏差 (Optimistic Bias)

### 問題：$E_m$ 是否為 $E_{out}(g_m)$ 的無偏估計？

**答案**: **不是！**

### 為什麼會有樂觀偏差？

1. **模型選擇過程**：
   - 我們計算了 $M$ 個模型的驗證誤差 $E_1, E_2, \ldots, E_M$
   - 選擇 $m^* = \arg\min_m E_m$
   - 此時 $E_{m^*} \leq E_m$ 對所有 $m$ 成立

2. **選擇偏差**：
   - 我們選擇了「運氣最好」的模型
   - $E_{m^*}$ 會系統性地**低估**真實的 $E_{out}(g_{m^*})$
   - 這就是所謂的「樂觀偏差」

### 實驗中的體現

從我們的實驗結果：
- 如果使用驗證集選擇模型，會選擇 $Q=1$
- 其驗證誤差 $E_{val} = 0.4384$
- 但這個誤差值經過了「選擇最佳」的過程
- 因此對真實的泛化誤差來說是**樂觀的**（偏低的）估計

### 解決方案

為了獲得無偏估計，需要：
1. 使用**獨立的測試集**（未參與模型選擇）
2. 或使用**交叉驗證** (Cross-Validation)
3. 或考慮**正則化** (Regularization) 來懲罰複雜度

---

## 🔑 關鍵結論

### 1. 訓練誤差不可靠
- $E_{in}$ 會隨模型複雜度增加而下降
- 但這**不代表**模型在新數據上表現更好
- 永遠不要只看訓練誤差來選擇模型！

### 2. 測試誤差呈 U 型曲線
- 存在一個**最佳複雜度**
- 過低：欠擬合（高偏差）
- 過高：過擬合（高變異數）

### 3. 樣本數的重要性
- 在 $N=35$ 這樣的小樣本下，過擬合特別嚴重
- 樣本越多，可以支撐越複雜的模型

### 4. 模型選擇的挑戰
- 選擇驗證誤差最小的模型會引入樂觀偏差
- 需要更謹慎的評估策略

---

## 💡 實務建議

1. **永遠使用獨立的測試集**
   - 訓練集：訓練模型
   - 驗證集：選擇模型/調參
   - 測試集：最終評估（只用一次！）

2. **注意樣本數與模型複雜度的匹配**
   - 經驗法則：參數數量 << 樣本數
   - 本實驗中：$N=35$，$Q=15$ 時有16個參數（過多）

3. **使用正則化**
   - Ridge Regression (L2)
   - Lasso Regression (L1)
   - 可以在高複雜度模型中降低過擬合

4. **交叉驗證**
   - K-fold Cross-Validation
   - 更充分利用有限的數據
   - 提供更穩健的模型評估

---

## 📚 與課程內容的對應

這個實驗完美展示了《Learning From Data》第4章的核心概念：

1. **VC 理論**: 模型複雜度（VC dimension）與泛化能力的關係
2. **泛化界**: $E_{out} \leq E_{in} + \Omega(N, d_{VC})$
3. **正則化**: 平衡擬合與複雜度的策略
4. **驗證**: 如何在實務中選擇模型

---

## ✅ 實驗完成檢查清單

- ✅ **程式實作**: 完成數值模擬程式
- ✅ **視覺化**: 生成訓練/測試誤差曲線圖
- ✅ **模型比較**: 比較不同複雜度下的過擬合情況
- ✅ **圖表說明**: 詳細解釋誤差隨複雜度的變化
- ✅ **理論分析**: 說明偏差-變異數權衡和樂觀偏差

---

**實驗日期**: 2025年10月5日  
**實驗者**: Kai  
**實驗編號**: Exercise 4.8
